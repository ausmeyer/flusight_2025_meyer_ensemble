---
title: "TwoStage Ensemble Retrospective Analysis: Complete Evaluation"
subtitle: "Ensemble of Saved Models vs FluSight-baseline - All Locations"
author: "Two-Stage Model Ensemble Retrospective Analysis"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    code_folding: hide
    fig_width: 14
    fig_height: 8
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.width = 14,
  fig.height = 8
)

# CONFIGURATION
# - Set to TRUE to include ARIMA in ensemble, FALSE to exclude
INCLUDE_ARIMA <- TRUE
# - Directories to scan for additional external model CSVs (e.g., SVM)
#   These paths are relative to this Rmd's working directory
EXTERNAL_MODEL_DIRS <- c(
  "retrospective",                                  # local drop-in
  "../../../flusight_2025_svm/forecasts/retrospective" # SVM project (if present)
)

# Load required libraries
library(dplyr)
library(ggplot2)
library(plotly)
library(DT)
library(readr)
library(lubridate)
library(scales)
library(htmlwidgets)
library(crosstalk)
library(purrr)
library(tidyr)
library(knitr)
library(gridExtra)

# Install and load scoringutils if not available
if (!require(scoringutils, quietly = TRUE)) {
  install.packages("scoringutils")
  library(scoringutils)
}
```

# Executive Summary

This comprehensive analysis compares retrospective out-of-sample forecasts from:

- **TwoStage-Ensemble**: Averaged ensemble of all two-stage models in saved_models directory
- **FluSight-baseline**: CDC standard persistence baseline model

The ensemble averages quantile forecasts across all available models for each horizon, creating a robust combined forecast.

Key metrics include point forecast accuracy (MAE, RMSE), probabilistic forecast quality (WIS), and coverage analysis across available horizons.

```{r load-data}
# Load forecast data for both models
cat("Loading retrospective forecast data...\n")

# First, load baseline data (same as original)
baseline_files <- list.files("retrospective", pattern = "Flusight-baseline_h[1-4]_forecasts.csv", full.names = TRUE)
available_horizons_baseline <- unique(as.numeric(gsub(".*_h([1-4])_.*", "\\1", baseline_files)))

# Load baseline data
models_data <- list()

for (horizon in available_horizons_baseline) {
  # FluSight-baseline
  baseline_file <- sprintf("retrospective/Flusight-baseline_h%d_forecasts.csv", horizon)
  if (file.exists(baseline_file)) {
    baseline_data <- read_csv(baseline_file, show_col_types = FALSE)
    # Adjust horizon numbering if needed
    if (all(baseline_data$horizon == (horizon - 1))) {
      baseline_data$horizon <- horizon
    }
    baseline_data$model <- "FluSight-baseline"
    # Filter to only include forecasts with target dates on or after 11/23/2024
    baseline_data <- baseline_data %>%
      mutate(target_end_date = as.Date(target_end_date)) %>%
      filter(target_end_date >= as.Date("2024-11-23"))
    models_data[[paste0("baseline_h", horizon)]] <- baseline_data
    cat(sprintf("Loaded FluSight-baseline horizon %d: %d rows (after filtering for dates >= 2024-11-23)\n", horizon, nrow(baseline_data)))
  }
}

# Now load and ensemble the saved models
saved_models_dir <- "retrospective/saved_models"
model_folders <- list.dirs(saved_models_dir, full.names = TRUE, recursive = FALSE)

# Conditionally include ARIMA based on configuration
if (!INCLUDE_ARIMA) {
  model_folders <- model_folders[!grepl("arima", basename(model_folders), ignore.case = TRUE)]
  cat(sprintf("\nFound %d model folders in saved_models directory (ARIMA excluded)\n", length(model_folders)))
} else {
  cat(sprintf("\nFound %d model folders in saved_models directory (ARIMA included)\n", length(model_folders)))
}

# Track which models are included by horizon and overall
included_models_by_horizon <- list()

# Process each horizon
for (horizon in 1:4) {
  all_model_data <- list()
  model_count <- 0
  included_models_current <- c()
  
  # Load data from each model folder
  for (folder in model_folders) {
    model_name <- basename(folder)
    
    # Check for different file naming patterns
    if (model_name == "arima") {
      # ARIMA uses different naming convention
      model_file <- file.path(folder, sprintf("ARIMA_h%d_forecasts.csv", horizon))
    } else {
      # Two-stage models use this naming
      model_file <- file.path(folder, sprintf("TwoStage-FrozenMu_h%d_forecasts.csv", horizon))
    }
    
    if (file.exists(model_file)) {
      model_data <- read_csv(model_file, show_col_types = FALSE)
      # Adjust horizon numbering if needed
      if (all(model_data$horizon == (horizon - 1))) {
        model_data$horizon <- horizon
      }
      model_data$source_model <- model_name  # Track source model
      # Filter to only include forecasts with target dates on or after 11/23/2024
      model_data <- model_data %>%
        mutate(target_end_date = as.Date(target_end_date)) %>%
        filter(target_end_date >= as.Date("2024-11-23"))
      
      all_model_data[[model_name]] <- model_data
      model_count <- model_count + 1
      included_models_current <- c(included_models_current, model_name)
    }
  }

  # Also look for external SVM CSVs for this horizon in configured directories
  svm_files <- unique(unlist(lapply(EXTERNAL_MODEL_DIRS, function(d) {
    if (!dir.exists(d)) return(character(0))
    list.files(
      d,
      pattern = paste0("^svm.*_h", horizon, ".*\\.csv$"),
      full.names = TRUE,
      ignore.case = TRUE
    )
  })))

  if (length(svm_files) > 0) {
    for (svm_file in svm_files) {
      # Derive model name from file (e.g., svm_t25_h1.csv -> svm_t25)
      svm_base <- basename(svm_file)
      svm_name <- sub("_h[0-9].*$", "", svm_base)
      
      svm_data <- read_csv(svm_file, show_col_types = FALSE)
      # Normalize column names to match expected schema
      # SVM uses columns: type, quantile; convert to output_type, output_type_id
      if ("type" %in% names(svm_data)) {
        svm_data <- svm_data %>% rename(output_type = type)
      }
      if ("quantile" %in% names(svm_data)) {
        svm_data <- svm_data %>% rename(output_type_id = quantile)
      }
      # Ensure correct types
      if ("output_type_id" %in% names(svm_data)) {
        svm_data$output_type_id <- as.numeric(svm_data$output_type_id)
      }
      # Align horizon numbering if needed
      if ("horizon" %in% names(svm_data) && all(svm_data$horizon == (horizon - 1))) {
        svm_data$horizon <- horizon
      }
      # Stamp source model and filter dates
      svm_data$source_model <- svm_name
      svm_data <- svm_data %>%
        mutate(target_end_date = as.Date(target_end_date)) %>%
        filter(target_end_date >= as.Date("2024-11-23"))
      
      all_model_data[[svm_name]] <- svm_data
      model_count <- model_count + 1
      included_models_current <- c(included_models_current, svm_name)
    }
  }
  
  # Record models included for this horizon
  if (length(included_models_current) > 0) {
    included_models_by_horizon[[paste0("h", horizon)]] <- sort(unique(included_models_current))
  }
  
  if (model_count > 0) {
    cat(sprintf("Horizon %d: Loaded %d models for ensemble\n", horizon, model_count))
    
    # Combine all model data
    combined_data <- bind_rows(all_model_data)
    
    # Average the quantile forecasts across models
    # Group by all key fields except source_model and average the values
    # Note: 'target' strings may differ across models; exclude it from grouping
    ensemble_data <- combined_data %>%
      group_by(reference_date, horizon, target_end_date, location, 
               output_type, output_type_id) %>%
      summarise(
        value = mean(value, na.rm = TRUE),  # Average across models
        n_models = n(),  # Track how many models contributed
        .groups = "drop"
      ) %>%
      select(-n_models) %>%  # Remove the count column for final output
      mutate(model = "TwoStage-Ensemble")  # Label as ensemble
    
    models_data[[paste0("twostage_h", horizon)]] <- ensemble_data
    cat(sprintf("Created ensemble for horizon %d: %d rows\n", horizon, nrow(ensemble_data)))
  }
}

# Determine available horizons (where we have both baseline and ensemble)
available_horizons <- c()
for (h in 1:4) {
  if (!is.null(models_data[[paste0("baseline_h", h)]]) && 
      !is.null(models_data[[paste0("twostage_h", h)]])) {
    available_horizons <- c(available_horizons, h)
  }
}

cat(sprintf("\nAvailable horizons for comparison: %s\n", paste(sort(available_horizons), collapse = ", ")))

# Compute overall list of included models and external models
included_models_all <- sort(unique(unlist(included_models_by_horizon)))
external_models_included <- setdiff(included_models_all, basename(model_folders))

# Load actual hospitalization data
actual_data_file <- "../data/imputed_and_stitched_hosp_2025-05-24.csv"
if (file.exists(actual_data_file)) {
  actual_raw <- read_csv(actual_data_file, show_col_types = FALSE)
  actual_data <- actual_raw %>%
    select(location_name, date, total_hosp) %>%
    rename(state_name = location_name, actual_value = total_hosp) %>%
    mutate(date = as.Date(date)) %>%
    filter(!is.na(actual_value), date >= as.Date("2024-11-23"))
  
  # Create location mapping from state names to FIPS codes
  location_to_fips <- c(
    'Alabama' = '01', 'Alaska' = '02', 'Arizona' = '04', 'Arkansas' = '05',
    'California' = '06', 'Colorado' = '08', 'Connecticut' = '09', 'Delaware' = '10',
    'District of Columbia' = '11', 'Florida' = '12', 'Georgia' = '13', 'Hawaii' = '15',
    'Idaho' = '16', 'Illinois' = '17', 'Indiana' = '18', 'Iowa' = '19',
    'Kansas' = '20', 'Kentucky' = '21', 'Louisiana' = '22', 'Maine' = '23',
    'Maryland' = '24', 'Massachusetts' = '25', 'Michigan' = '26', 'Minnesota' = '27',
    'Mississippi' = '28', 'Missouri' = '29', 'Montana' = '30', 'Nebraska' = '31',
    'Nevada' = '32', 'New Hampshire' = '33', 'New Jersey' = '34', 'New Mexico' = '35',
    'New York' = '36', 'North Carolina' = '37', 'North Dakota' = '38', 'Ohio' = '39',
    'Oklahoma' = '40', 'Oregon' = '41', 'Pennsylvania' = '42', 'Puerto Rico' = '72',
    'Rhode Island' = '44', 'South Carolina' = '45', 'South Dakota' = '46', 'Tennessee' = '47',
    'Texas' = '48', 'Utah' = '49', 'Vermont' = '50', 'Virginia' = '51',
    'Virgin Islands' = '78', 'Guam' = '66',
    'Washington' = '53', 'West Virginia' = '54', 'Wisconsin' = '55', 'Wyoming' = '56',
    'United States' = 'US'
  )
  
  # Add FIPS codes to actual data
  actual_data$location <- location_to_fips[actual_data$state_name]
  
  cat(sprintf("\nLoaded actual hospitalization data: %d rows\n", nrow(actual_data)))
  cat(sprintf("Date range: %s to %s\n", min(actual_data$date), max(actual_data$date)))
  cat(sprintf("Number of locations: %d\n", n_distinct(actual_data$location)))
} else {
  stop("Actual data file not found!")
}

# FIPS to state name mapping
location_mapping <- c(
  '01' = 'Alabama', '02' = 'Alaska', '04' = 'Arizona', '05' = 'Arkansas',
  '06' = 'California', '08' = 'Colorado', '09' = 'Connecticut', '10' = 'Delaware',
  '11' = 'District of Columbia', '12' = 'Florida', '13' = 'Georgia', '15' = 'Hawaii',
  '16' = 'Idaho', '17' = 'Illinois', '18' = 'Indiana', '19' = 'Iowa',
  '20' = 'Kansas', '21' = 'Kentucky', '22' = 'Louisiana', '23' = 'Maine',
  '24' = 'Maryland', '25' = 'Massachusetts', '26' = 'Michigan', '27' = 'Minnesota',
  '28' = 'Mississippi', '29' = 'Missouri', '30' = 'Montana', '31' = 'Nebraska',
  '32' = 'Nevada', '33' = 'New Hampshire', '34' = 'New Jersey', '35' = 'New Mexico',
  '36' = 'New York', '37' = 'North Carolina', '38' = 'North Dakota', '39' = 'Ohio',
  '40' = 'Oklahoma', '41' = 'Oregon', '42' = 'Pennsylvania', '72' = 'Puerto Rico',
  '44' = 'Rhode Island', '45' = 'South Carolina', '46' = 'South Dakota', '47' = 'Tennessee',
  '48' = 'Texas', '49' = 'Utah', '50' = 'Vermont', '51' = 'Virginia',
  '78' = 'Virgin Islands', '66' = 'Guam',
  '53' = 'Washington', '54' = 'West Virginia', '55' = 'Wisconsin', '56' = 'Wyoming',
  'US' = 'United States'
)

# Report ensemble composition
cat("\n=== ENSEMBLE COMPOSITION ===\n")
cat(sprintf("Number of model folders processed (saved_models): %d\n", length(model_folders)))
if (length(model_folders) > 0) {
  cat("Saved model folders included:\n")
  for (folder in model_folders) {
    cat(sprintf("  - %s\n", basename(folder)))
  }
}
if (length(external_models_included) > 0) {
  cat("External models included (from EXTERNAL_MODEL_DIRS):\n")
  for (mdl in external_models_included) {
    cat(sprintf("  - %s\n", mdl))
  }
} else {
  cat("External models included: none detected\n")
}

cat("Models used in ensemble by horizon:\n")
for (h in names(included_models_by_horizon)) {
  cat(sprintf("  %s: %s\n", h, paste(included_models_by_horizon[[h]], collapse=", ")))
}
```

```{r prepare-functions}
# Function to prepare quantile data for plotting
prepare_quantile_data <- function(data) {
  quantile_data <- data %>%
    filter(output_type == 'quantile') %>%
    mutate(
      output_type_id = as.numeric(output_type_id),
      value = as.numeric(value)
    )
  
  quantile_summary <- quantile_data %>%
    group_by(reference_date, target_end_date, location, model) %>%
    summarise(
      q01 = value[which.min(abs(output_type_id - 0.01))],
      q05 = value[which.min(abs(output_type_id - 0.05))],
      q25 = value[which.min(abs(output_type_id - 0.25))],
      median = value[which.min(abs(output_type_id - 0.5))],
      q75 = value[which.min(abs(output_type_id - 0.75))],
      q95 = value[which.min(abs(output_type_id - 0.95))],
      q99 = value[which.min(abs(output_type_id - 0.99))],
      .groups = "drop"
    ) %>%
    mutate(
      q01 = pmin(q01, q05, q25, median, na.rm = TRUE),
      q05 = pmin(q05, q25, median, na.rm = TRUE),
      q25 = pmin(q25, median, na.rm = TRUE),
      q75 = pmax(q75, median, na.rm = TRUE),
      q95 = pmax(q95, q75, median, na.rm = TRUE),
      q99 = pmax(q99, q95, q75, median, na.rm = TRUE)
    )
  
  return(quantile_summary)
}

# Function to create horizon facet plot for ensemble (includes baseline)
create_horizon_facet_plot_ensemble <- function(horizon_data, truth_data, horizon, location_mapping) {
  # Prepare data
  plot_data <- prepare_quantile_data(horizon_data)
  
  # Remove any rows with NA or invalid locations
  plot_data <- plot_data %>% 
    filter(!is.na(location) & location != "" & location != "location")
  
  # Debug: Check for unexpected locations
  unknown_locs <- unique(plot_data$location[!plot_data$location %in% names(location_mapping)])
  if (length(unknown_locs) > 0) {
    cat("Warning: Unknown locations found:", paste(unknown_locs, collapse=", "), "\n")
  }
  
  # Add location names
  plot_data$location_name <- sapply(plot_data$location, function(loc) {
    if (loc %in% names(location_mapping)) {
      location_mapping[loc]
    } else {
      # Don't create entries for NA or empty locations
      if (is.na(loc) || loc == "") {
        return(NA)
      }
      paste("Location", loc)
    }
  })
  
  # Remove any rows with NA location names
  plot_data <- plot_data %>% filter(!is.na(location_name))
  
  # Prepare truth data
  truth_plot <- truth_data %>%
    filter(!is.na(location) & location != "" & location != "location") %>%
    mutate(location_name = sapply(location, function(loc) {
      if (loc %in% names(location_mapping)) {
        location_mapping[loc]
      } else {
        paste("Location", loc)
      }
    }))
  
  # Create plot with both baseline and ensemble
  p <- ggplot() +
    # FluSight-baseline (Purple) - plot first
    geom_ribbon(data = plot_data %>% filter(model == "FluSight-baseline"),
                aes(x = target_end_date, ymin = q01, ymax = q99),
                fill = "#d9a8d9", alpha = 0.3) +
    geom_ribbon(data = plot_data %>% filter(model == "FluSight-baseline"),
                aes(x = target_end_date, ymin = q05, ymax = q95),
                fill = "#bf7abf", alpha = 0.4) +
    geom_ribbon(data = plot_data %>% filter(model == "FluSight-baseline"),
                aes(x = target_end_date, ymin = q25, ymax = q75),
                fill = "#8e4a8e", alpha = 0.5) +
    geom_line(data = plot_data %>% filter(model == "FluSight-baseline"),
              aes(x = target_end_date, y = median),
              color = "#5d1a5d", linewidth = 1.0, linetype = "dashed") +
    
    # TwoStage-Ensemble (Green)
    geom_ribbon(data = plot_data %>% filter(model == "TwoStage-Ensemble"),
                aes(x = target_end_date, ymin = q01, ymax = q99),
                fill = "#a8d9a8", alpha = 0.3) +
    geom_ribbon(data = plot_data %>% filter(model == "TwoStage-Ensemble"),
                aes(x = target_end_date, ymin = q05, ymax = q95),
                fill = "#7ab37a", alpha = 0.4) +
    geom_ribbon(data = plot_data %>% filter(model == "TwoStage-Ensemble"),
                aes(x = target_end_date, ymin = q25, ymax = q75),
                fill = "#4d8d4d", alpha = 0.5) +
    geom_line(data = plot_data %>% filter(model == "TwoStage-Ensemble"),
              aes(x = target_end_date, y = median),
              color = "#1f5f1f", linewidth = 1.0) +
    
    # Ground truth (black)
    geom_line(data = truth_plot,
              aes(x = date, y = actual_value),
              color = "black", linewidth = 1.2) +
    geom_point(data = truth_plot,
               aes(x = date, y = actual_value),
               color = "black", size = 1, alpha = 0.7) +
    
    # Facet by location
    facet_wrap(~ location_name, scales = "free_y", ncol = 6) +
    
    # Styling
    scale_x_date(labels = date_format("%m/%d"), breaks = pretty_breaks(n = 4)) +
    scale_y_continuous(labels = comma_format(), breaks = pretty_breaks(n = 4)) +
    labs(
      title = paste("Horizon", horizon, "-", horizon, "Week(s) Ahead Forecasts"),
      subtitle = "Purple: FluSight-baseline (dashed) | Green: TwoStage-Ensemble (solid) | Black: Actual",
      x = NULL,
      y = "Hospitalizations"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11),
      strip.text = element_text(size = 9, face = "bold"),
      axis.text = element_text(size = 7),
      axis.title = element_text(size = 9),
      panel.grid.minor = element_blank(),
      panel.spacing = unit(0.5, "lines")
    )
  
  return(p)
}

# Function to create comparison plot
create_comparison_plot <- function(loc, horizon_data, truth_data, horizon_label) {
  
  loc_data <- horizon_data %>% filter(location == loc)
  loc_truth <- truth_data %>% filter(location == loc)
  
  if (nrow(loc_data) == 0) {
    return(NULL)
  }
  
  # Create plot
  p <- ggplot()
  
  # FluSight-baseline (Purple)
  baseline_data <- loc_data %>% filter(model == "FluSight-baseline")
  if (nrow(baseline_data) > 0) {
    p <- p +
      geom_ribbon(data = baseline_data, aes(x = target_end_date, ymin = q01, ymax = q99),
                 fill = "#d9a8d9", alpha = 0.3) +
      geom_ribbon(data = baseline_data, aes(x = target_end_date, ymin = q05, ymax = q95),
                 fill = "#bf7abf", alpha = 0.4) +
      geom_ribbon(data = baseline_data, aes(x = target_end_date, ymin = q25, ymax = q75),
                 fill = "#8e4a8e", alpha = 0.5) +
      geom_line(data = baseline_data, aes(x = target_end_date, y = median),
               color = "#5d1a5d", linewidth = 1.0, linetype = "dashed")
  }
  
  # TwoStage-Ensemble (Green for ensemble)
  twostage_data <- loc_data %>% filter(model == "TwoStage-Ensemble")
  if (nrow(twostage_data) > 0) {
    p <- p +
      geom_ribbon(data = twostage_data, aes(x = target_end_date, ymin = q01, ymax = q99),
                 fill = "#a8d9a8", alpha = 0.3) +
      geom_ribbon(data = twostage_data, aes(x = target_end_date, ymin = q05, ymax = q95),
                 fill = "#7ab37a", alpha = 0.4) +
      geom_ribbon(data = twostage_data, aes(x = target_end_date, ymin = q25, ymax = q75),
                 fill = "#4d8d4d", alpha = 0.5) +
      geom_line(data = twostage_data, aes(x = target_end_date, y = median),
               color = "#1f5f1f", linewidth = 1.0)
  }
  
  # Ground truth
  if (nrow(loc_truth) > 0) {
    p <- p +
      geom_line(data = loc_truth, aes(x = target_end_date, y = actual_value),
               color = "black", linewidth = 1.2) +
      geom_point(data = loc_truth, aes(x = target_end_date, y = actual_value),
                color = "black", size = 1.5, alpha = 0.7)
  }
  
  # Styling
  location_name <- ifelse(loc %in% names(location_mapping), 
                         location_mapping[loc], 
                         paste("Location", loc))
  
  p <- p +
    scale_x_date(labels = date_format("%m/%d"), breaks = pretty_breaks(n = 5)) +
    scale_y_continuous(labels = comma_format(), breaks = pretty_breaks(n = 5)) +
    labs(
      title = paste(location_name, "-", horizon_label),
      x = NULL,
      y = "Hospitalizations"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 10, face = "bold"),
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      panel.grid.minor = element_blank()
    )
  
  return(p)
}
```

# Relative WIS by Horizon

```{r horizon-wis}
# Calculate WIS for each horizon separately using CDC methodology
cat("Calculating relative WIS by horizon using CDC methodology...\n")
cat("(Log-transformed data, geometric mean across locations, excluding PR and US)\n\n")

horizon_wis_results <- list()

for (h in available_horizons) {
  baseline_key <- paste0("baseline_h", h)
  twostage_key <- paste0("twostage_h", h)
  
  if (!is.null(models_data[[baseline_key]]) && !is.null(models_data[[twostage_key]])) {
    # Combine data for this horizon
    h_data <- bind_rows(models_data[[baseline_key]], models_data[[twostage_key]])
    
    # Convert dates
    h_data$reference_date <- as.Date(h_data$reference_date)
    h_data$target_end_date <- as.Date(h_data$target_end_date)
    
    # Get actual values
    h_truth <- h_data %>%
      select(target_end_date, location) %>%
      distinct() %>%
      left_join(actual_data, by = c("target_end_date" = "date", "location" = "location"))
    
    # Prepare WIS data with log transformation per CDC methodology
    wis_ready_h <- h_data %>%
      filter(output_type == 'quantile') %>%
      mutate(
        output_type_id = as.numeric(output_type_id),
        value = as.numeric(value)
      ) %>%
      left_join(h_truth %>% select(target_end_date, location, actual_value),
                by = c("target_end_date", "location")) %>%
      filter(!is.na(actual_value)) %>%
      mutate(
        # Apply log transformation (log(x + 1) to handle zeros)
        value_log = log(value + 1),
        actual_value_log = log(actual_value + 1)
      ) %>%
      select(model, location, reference_date, target_end_date, actual_value_log, 
             output_type_id, value_log) %>%
      rename(
        prediction = value_log,
        true_value = actual_value_log,
        quantile = output_type_id
      )
    
    if (nrow(wis_ready_h) > 0) {
      # Calculate WIS scores
      wis_scores_h <- wis_ready_h %>%
        score()
      
      # Find locations that both models have, excluding PR and US
      common_locations_h <- wis_scores_h %>%
        group_by(location, model) %>%
        summarise(n = n(), .groups = "drop") %>%
        group_by(location) %>%
        summarise(n_models = n_distinct(model), .groups = "drop") %>%
        filter(n_models == 2) %>%
        pull(location)
      
      common_locations_h <- common_locations_h[!common_locations_h %in% c("72", "US")]
      
      # Filter to only common locations
      wis_scores_common_h <- wis_scores_h %>%
        filter(location %in% common_locations_h)
      
      # Calculate geometric mean WIS by location first
      wis_by_loc_h <- wis_scores_common_h %>%
        group_by(model, location) %>%
        summarise(
          mean_wis_loc = mean(interval_score, na.rm = TRUE),
          .groups = "drop"
        )
      
      # Overall WIS using geometric mean across locations (CDC methodology)
      overall_wis_h <- wis_by_loc_h %>%
        group_by(model) %>%
        summarise(
          n_locations = n_distinct(location),
          geometric_mean_wis = exp(mean(log(mean_wis_loc), na.rm = TRUE)),
          .groups = "drop"
        )
      
      # Calculate relative WIS
      baseline_wis_h <- overall_wis_h$geometric_mean_wis[overall_wis_h$model == "FluSight-baseline"]
      twostage_wis_h <- overall_wis_h$geometric_mean_wis[overall_wis_h$model == "TwoStage-Ensemble"]
      
      if (length(baseline_wis_h) > 0 && length(twostage_wis_h) > 0) {
        relative_wis_h <- twostage_wis_h / baseline_wis_h
        
        horizon_wis_results[[h]] <- data.frame(
          horizon = h,
          n_locations = length(common_locations_h),
          baseline_wis = baseline_wis_h,
          twostage_wis = twostage_wis_h,
          relative_wis = relative_wis_h,
          improvement = (1 - relative_wis_h) * 100
        )
      }
    }
  }
}

# Display results
if (length(horizon_wis_results) > 0) {
  horizon_wis_df <- bind_rows(horizon_wis_results)
  
  cat("RELATIVE WIS BY HORIZON:\n")
  cat("========================\n\n")
  
  for (i in 1:nrow(horizon_wis_df)) {
    cat(sprintf("Horizon %d (%d week%s ahead):\n", 
                horizon_wis_df$horizon[i], 
                horizon_wis_df$horizon[i],
                if(horizon_wis_df$horizon[i] > 1) "s" else ""))
    cat(sprintf("  Locations compared: %d\n", horizon_wis_df$n_locations[i]))
    cat(sprintf("  FluSight-baseline Geometric Mean WIS: %.3f\n", horizon_wis_df$baseline_wis[i]))
    cat(sprintf("  TwoStage-Ensemble Geometric Mean WIS: %.3f\n", horizon_wis_df$twostage_wis[i]))
    cat(sprintf("  Relative WIS: %.4f\n", horizon_wis_df$relative_wis[i]))
    cat(sprintf("  Performance: %.1f%% %s than baseline\n\n", 
                abs(horizon_wis_df$improvement[i]),
                if(horizon_wis_df$improvement[i] > 0) "BETTER" else "WORSE"))
  }
  
  # Display summary table
  datatable(
    horizon_wis_df %>%
      select(horizon, n_locations, baseline_wis, twostage_wis, relative_wis, improvement) %>%
      mutate(
        horizon = paste0("Horizon ", horizon, " (", horizon, " week", ifelse(horizon > 1, "s", ""), " ahead)")
      ),
    caption = "Relative WIS by Horizon (Log-transformed data, Geometric mean, excluding PR and US)",
    options = list(
      pageLength = 5,
      dom = 't',
      columnDefs = list(list(className = 'dt-center', targets = "_all"))
    ),
    rownames = FALSE,
    colnames = c("Horizon", "Locations", "Baseline WIS", "Ensemble WIS", "Relative WIS", "Improvement %")
  ) %>%
    formatRound(columns = c("baseline_wis", "twostage_wis", "relative_wis", "improvement"), digits = 3)
}
```

# Total Combined Relative WIS

```{r total-wis}
# Calculate total combined WIS across all horizons and locations
cat("Calculating total combined relative WIS across all horizons...\n\n")

all_wis_data <- list()

for (h in available_horizons) {
  baseline_key <- paste0("baseline_h", h)
  twostage_key <- paste0("twostage_h", h)
  
  if (!is.null(models_data[[baseline_key]]) && !is.null(models_data[[twostage_key]])) {
    # Combine data
    h_data <- bind_rows(models_data[[baseline_key]], models_data[[twostage_key]])
    
    # Convert dates
    h_data$reference_date <- as.Date(h_data$reference_date)
    h_data$target_end_date <- as.Date(h_data$target_end_date)
    
    # Get actual values
    h_truth <- h_data %>%
      select(target_end_date, location) %>%
      distinct() %>%
      left_join(actual_data, by = c("target_end_date" = "date", "location" = "location"))
    
    # Prepare WIS data with log transformation per CDC methodology
    wis_ready <- h_data %>%
      filter(output_type == 'quantile') %>%
      mutate(
        output_type_id = as.numeric(output_type_id),
        value = as.numeric(value)
      ) %>%
      left_join(h_truth %>% select(target_end_date, location, actual_value),
                by = c("target_end_date", "location")) %>%
      filter(!is.na(actual_value)) %>%
      mutate(
        # Apply log transformation (log(x + 1) to handle zeros)
        value_log = log(value + 1),
        actual_value_log = log(actual_value + 1),
        horizon = h
      ) %>%
      select(model, location, reference_date, target_end_date, actual_value_log, 
             output_type_id, value_log, horizon) %>%
      rename(
        prediction = value_log,
        true_value = actual_value_log,
        quantile = output_type_id
      )
    
    all_wis_data[[h]] <- wis_ready
  }
}

# Combine all horizons
combined_wis_data <- bind_rows(all_wis_data)

if (nrow(combined_wis_data) > 0) {
  # Calculate WIS scores
  wis_scores <- combined_wis_data %>%
    score()
  
  # Find locations that both models have
  common_locations <- wis_scores %>%
    group_by(location, model) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(location) %>%
    summarise(n_models = n_distinct(model), .groups = "drop") %>%
    filter(n_models == 2) %>%
    pull(location)
  
  # Exclude Puerto Rico (72) and US national level per CDC methodology
  common_locations <- common_locations[!common_locations %in% c("72", "US")]
  
  # Filter to only common locations for fair comparison
  wis_scores_common <- wis_scores %>%
    filter(location %in% common_locations)
  
  # Calculate geometric mean WIS by location first
  wis_by_loc_model <- wis_scores_common %>%
    group_by(model, location) %>%
    summarise(
      mean_wis_loc = mean(interval_score, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Overall WIS using geometric mean across locations (CDC methodology)
  overall_wis <- wis_by_loc_model %>%
    group_by(model) %>%
    summarise(
      n_locations = n_distinct(location),
      # Geometric mean = exp(mean(log(x)))
      geometric_mean_wis = exp(mean(log(mean_wis_loc), na.rm = TRUE)),
      arithmetic_mean_wis = mean(mean_wis_loc, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Also keep simple count statistics
  overall_stats <- wis_scores_common %>%
    group_by(model) %>%
    summarise(
      n_forecasts = n(),
      median_wis = median(interval_score, na.rm = TRUE),
      .groups = "drop"
    )
  
  overall_wis <- overall_wis %>%
    left_join(overall_stats, by = "model")
  
  # Calculate relative WIS using geometric means
  baseline_wis <- overall_wis$geometric_mean_wis[overall_wis$model == "FluSight-baseline"]
  twostage_wis <- overall_wis$geometric_mean_wis[overall_wis$model == "TwoStage-Ensemble"]
  
  if (length(baseline_wis) > 0 && length(twostage_wis) > 0) {
    relative_wis_total <- twostage_wis / baseline_wis
    
    cat("TOTAL COMBINED RELATIVE WIS (All Horizons and Locations):\n")
    cat("==========================================================\n\n")
    cat("Note: WIS calculated on log-transformed data per CDC methodology\n")
    cat("      Excludes Puerto Rico and US national level\n")
    cat(sprintf("Number of locations compared: %d (50 states + DC)\n", length(common_locations)))
    cat(sprintf("FluSight-baseline Geometric Mean WIS: %.2f\n", baseline_wis))
    cat(sprintf("TwoStage-Ensemble Geometric Mean WIS: %.2f\n", twostage_wis))
    cat(sprintf("\nTwoStage-Ensemble Relative WIS: %.4f\n", relative_wis_total))
    cat(sprintf("Performance: %.1f%% %s than baseline\n\n", 
                abs(1 - relative_wis_total) * 100,
                if(relative_wis_total < 1) "BETTER" else "WORSE"))
    
    # Display summary table
    overall_wis$relative_to_baseline <- overall_wis$geometric_mean_wis / baseline_wis
    
    display_table <- overall_wis %>%
      select(model, n_locations, n_forecasts, geometric_mean_wis, relative_to_baseline)
    
    datatable(
      display_table,
      caption = "Overall WIS Performance (Log-transformed data, Geometric mean across locations)",
      options = list(
        pageLength = 5,
        dom = 't',
        columnDefs = list(list(className = 'dt-center', targets = "_all"))
      ),
      rownames = FALSE,
      colnames = c("Model", "Locations", "Forecasts", "Geometric Mean WIS", "Relative to Baseline")
    ) %>%
      formatRound(columns = c("geometric_mean_wis", "relative_to_baseline"), digits = 4)
  }
  
  # Note: Per-horizon WIS already calculated and displayed above using geometric mean methodology
}
```

# Forecast Visualizations by Horizon

```{r h1-all-locations, fig.height=30, fig.width=16, eval=(1 %in% available_horizons)}
# Process horizon 1 using facet approach
if (1 %in% available_horizons) {
  cat("## Horizon 1: One Week Ahead\n\n")
  source("plot_functions.R")
  # Combine baseline and ensemble data for plotting
  combined_h1 <- bind_rows(
    models_data[["baseline_h1"]],
    models_data[["twostage_h1"]]
  )
  p1 <- create_horizon_facet_plot_ensemble(combined_h1, 
                                  actual_data, 1, location_mapping)
  if (!is.null(p1)) print(p1)
}
```

```{r h2-all-locations, fig.height=30, fig.width=16, eval=(2 %in% available_horizons)}
# Process horizon 2 using facet approach
if (2 %in% available_horizons) {
  cat("## Horizon 2: Two Weeks Ahead\n\n")
  source("plot_functions.R")
  # Combine baseline and ensemble data for plotting
  combined_h2 <- bind_rows(
    models_data[["baseline_h2"]],
    models_data[["twostage_h2"]]
  )
  p2 <- create_horizon_facet_plot_ensemble(combined_h2, 
                                  actual_data, 2, location_mapping)
  if (!is.null(p2)) print(p2)
}
```

```{r h3-all-locations, fig.height=30, fig.width=16, eval=(3 %in% available_horizons)}
# Process horizon 3 using facet approach
if (3 %in% available_horizons) {
  cat("## Horizon 3: Three Weeks Ahead\n\n")
  source("plot_functions.R")
  # Combine baseline and ensemble data for plotting
  combined_h3 <- bind_rows(
    models_data[["baseline_h3"]],
    models_data[["twostage_h3"]]
  )
  p3 <- create_horizon_facet_plot_ensemble(combined_h3, 
                                  actual_data, 3, location_mapping)
  if (!is.null(p3)) print(p3)
}
```

```{r h4-all-locations, fig.height=30, fig.width=16, eval=(4 %in% available_horizons)}
# Process horizon 4 using facet approach
if (4 %in% available_horizons) {
  cat("## Horizon 4: Four Weeks Ahead\n\n")
  source("plot_functions.R")
  # Combine baseline and ensemble data for plotting
  combined_h4 <- bind_rows(
    models_data[["baseline_h4"]],
    models_data[["twostage_h4"]]
  )
  p4 <- create_horizon_facet_plot_ensemble(combined_h4, 
                                  actual_data, 4, location_mapping)
  if (!is.null(p4)) print(p4)
}
```

# Detailed Performance Metrics

## Point Forecast Metrics (All Horizons)

```{r point-metrics-all}
# Calculate comprehensive metrics for all horizons
all_metrics <- list()

for (h in available_horizons) {
  baseline_key <- paste0("baseline_h", h)
  twostage_key <- paste0("twostage_h", h)
  
  if (!is.null(models_data[[baseline_key]]) && !is.null(models_data[[twostage_key]])) {
    h_data <- bind_rows(models_data[[baseline_key]], models_data[[twostage_key]])
    h_data$reference_date <- as.Date(h_data$reference_date)
    h_data$target_end_date <- as.Date(h_data$target_end_date)
    
    h_plot_data <- h_data %>%
      group_by(model) %>%
      do(prepare_quantile_data(.)) %>%
      ungroup()
    
    h_truth <- h_plot_data %>%
      select(target_end_date, location) %>%
      distinct() %>%
      left_join(actual_data, by = c("target_end_date" = "date", "location" = "location"))
    
    h_plot_data <- h_plot_data %>%
      left_join(h_truth %>% select(target_end_date, location, actual_value),
                by = c("target_end_date", "location"))
    
    h_metrics <- h_plot_data %>%
      filter(!is.na(actual_value)) %>%
      group_by(model, location) %>%
      summarise(
        horizon = h,
        n_forecasts = n(),
        mae = mean(abs(actual_value - median), na.rm = TRUE),
        rmse = sqrt(mean((actual_value - median)^2, na.rm = TRUE)),
        mape = mean(abs((actual_value - median) / pmax(actual_value, 1)) * 100, na.rm = TRUE),
        correlation = if(n() > 1) cor(actual_value, median, use = "complete.obs") else NA,
        bias = mean(median - actual_value, na.rm = TRUE),
        .groups = "drop"
      )
    
    all_metrics[[h]] <- h_metrics
  }
}

combined_metrics <- bind_rows(all_metrics)

# Overall summary
model_summary <- combined_metrics %>%
  group_by(model, horizon) %>%
  summarise(
    n_locations = n_distinct(location),
    avg_mae = mean(mae, na.rm = TRUE),
    avg_rmse = mean(rmse, na.rm = TRUE),
    avg_mape = mean(mape, na.rm = TRUE),
    avg_correlation = mean(correlation, na.rm = TRUE),
    avg_bias = mean(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric) & !c(horizon, n_locations), round, 3))

datatable(
  model_summary,
  caption = "Average Performance Metrics by Model and Horizon",
  options = list(
    pageLength = 10,
    scrollX = TRUE,
    columnDefs = list(list(className = 'dt-center', targets = "_all"))
  ),
  rownames = FALSE
)
```

## WIS by Location

```{r wis-by-location}
if (nrow(combined_wis_data) > 0) {
  # WIS by model and location - keeping n_forecasts
  # Using wis_scores_common which already excludes PR and US
  wis_by_location_raw <- wis_scores_common %>%
    group_by(model, location) %>%
    summarise(
      n_forecasts = n(),
      mean_wis = mean(interval_score, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Check what locations each model has
  baseline_locations <- wis_by_location_raw %>% 
    filter(model == "FluSight-baseline") %>% 
    select(location, baseline_wis = mean_wis, baseline_n = n_forecasts)
  
  twostage_locations <- wis_by_location_raw %>% 
    filter(model == "TwoStage-Ensemble") %>% 
    select(location, twostage_wis = mean_wis, twostage_n = n_forecasts)
  
  # Join only where both models have data
  wis_by_location <- baseline_locations %>%
    inner_join(twostage_locations, by = "location") %>%
    mutate(
      state = ifelse(location %in% names(location_mapping), 
                    location_mapping[location], 
                    paste("Location", location)),
      `FluSight-baseline` = baseline_wis,
      `TwoStage-Ensemble` = twostage_wis,
      relative_wis = twostage_wis / baseline_wis,
      improvement = (1 - relative_wis) * 100
    ) %>%
    arrange(desc(improvement))
  
  # Top performers
  cat("\nTOP 10 LOCATIONS WHERE TwoStage-Ensemble OUTPERFORMS BASELINE:\n")
  cat("==============================================================\n\n")
  top_10 <- head(wis_by_location, 10)
  print(kable(top_10 %>% select(state, `FluSight-baseline`, `TwoStage-Ensemble`, relative_wis, improvement), 
              digits = 2, col.names = c("Location", "Baseline WIS", "Ensemble WIS", "Relative WIS", "Improvement %")))
  
  # Bottom performers
  cat("\n\nLOCATIONS WHERE BASELINE PERFORMS BETTER:\n")
  cat("==========================================\n\n")
  bottom_performers <- wis_by_location %>% filter(improvement < 0) %>% head(10)
  if (nrow(bottom_performers) > 0) {
    print(kable(bottom_performers %>% select(state, `FluSight-baseline`, `TwoStage-Ensemble`, relative_wis, improvement), 
                digits = 2, col.names = c("Location", "Baseline WIS", "Ensemble WIS", "Relative WIS", "Improvement %")))
  } else {
    cat("TwoStage-Ensemble outperforms baseline in all locations!\n")
  }
  
  # Full location table
  datatable(
    wis_by_location %>% select(state, location, `FluSight-baseline`, `TwoStage-Ensemble`, relative_wis, improvement),
    caption = "WIS Performance by Location (All Horizons Combined)",
    options = list(
      pageLength = 20,
      scrollX = TRUE,
      columnDefs = list(list(className = 'dt-center', targets = "_all"))
    ),
    rownames = FALSE
  ) %>%
    formatRound(columns = c("FluSight-baseline", "TwoStage-Ensemble", "relative_wis", "improvement"), digits = 2)
}
```

## Coverage Analysis

```{r coverage-all-horizons}
# Calculate coverage for all horizons
coverage_results <- list()

for (h in available_horizons) {
  baseline_key <- paste0("baseline_h", h)
  twostage_key <- paste0("twostage_h", h)
  
  if (!is.null(models_data[[baseline_key]]) && !is.null(models_data[[twostage_key]])) {
    h_data <- bind_rows(models_data[[baseline_key]], models_data[[twostage_key]])
    h_data$reference_date <- as.Date(h_data$reference_date)
    h_data$target_end_date <- as.Date(h_data$target_end_date)
    
    h_plot_data <- h_data %>%
      group_by(model) %>%
      do(prepare_quantile_data(.)) %>%
      ungroup()
    
    h_truth <- h_plot_data %>%
      select(target_end_date, location) %>%
      distinct() %>%
      left_join(actual_data, by = c("target_end_date" = "date", "location" = "location"))
    
    h_plot_data <- h_plot_data %>%
      left_join(h_truth %>% select(target_end_date, location, actual_value),
                by = c("target_end_date", "location"))
    
    h_coverage <- h_plot_data %>%
      filter(!is.na(actual_value)) %>%
      group_by(model) %>%
      summarise(
        horizon = h,
        n_forecasts = n(),
        coverage_50 = mean(actual_value >= q25 & actual_value <= q75, na.rm = TRUE) * 100,
        coverage_90 = mean(actual_value >= q05 & actual_value <= q95, na.rm = TRUE) * 100,
        coverage_98 = mean(actual_value >= q01 & actual_value <= q99, na.rm = TRUE) * 100,
        .groups = "drop"
      )
    
    coverage_results[[h]] <- h_coverage
  }
}

combined_coverage <- bind_rows(coverage_results)

datatable(
  combined_coverage,
  caption = "Empirical Coverage of Prediction Intervals (%) by Horizon",
  options = list(
    pageLength = 10,
    scrollX = TRUE,
    columnDefs = list(list(className = 'dt-center', targets = "_all"))
  ),
  rownames = FALSE
) %>%
  formatRound(columns = c("coverage_50", "coverage_90", "coverage_98"), digits = 1)

# Overall coverage summary
overall_coverage <- combined_coverage %>%
  group_by(model) %>%
  summarise(
    total_forecasts = sum(n_forecasts),
    avg_coverage_50 = weighted.mean(coverage_50, n_forecasts),
    avg_coverage_90 = weighted.mean(coverage_90, n_forecasts),
    avg_coverage_98 = weighted.mean(coverage_98, n_forecasts),
    .groups = "drop"
  )

cat("\n\nOVERALL COVERAGE SUMMARY (All Horizons):\n")
cat("=========================================\n\n")
print(kable(overall_coverage, digits = 1))
```

# Key Findings

```{r summary}
cat("\nKEY PERFORMANCE INDICATOR:\n")
cat("==========================\n\n")

if (exists("relative_wis_total")) {
  cat(sprintf("Total Combined Relative WIS: %.4f\n", relative_wis_total))
  cat(sprintf("TwoStage-Ensemble is %.1f%% %s than baseline overall\n\n", 
              abs(1 - relative_wis_total) * 100,
              if(relative_wis_total < 1) "better" else "worse"))
}
```

---

# Technical Details

## Data Description
- **Forecast Period**: Retrospective out-of-sample evaluation
- **Models**: TwoStage-Ensemble (Average of all saved models) vs FluSight-baseline (CDC persistence)
- **Ensemble Method**: Simple average of quantile forecasts across all models
- **Available Horizons**: `r paste(available_horizons, collapse = ", ")` weeks ahead
- **Evaluation Scope**: 50 US states + DC (excludes Puerto Rico and US national level per CDC methodology)
- **Quantiles**: 23 standard CDC FluSight quantiles

## Metrics Explained
- **WIS (Weighted Interval Score)**: Proper scoring rule for quantile forecasts
  - Calculated on log-transformed data (log(count + 1)) per CDC methodology
  - Minimizes impact of count magnitude across jurisdictions
- **Relative WIS**: Ratio of geometric mean WIS (model) to geometric mean WIS (baseline)
  - Values < 1 indicate better performance than baseline
  - Uses geometric mean across locations for fair comparison
- **MAE/RMSE**: Point forecast accuracy metrics (on original scale)
- **Coverage**: Empirical coverage of prediction intervals

## Visualization Legend
- **Black line/points**: Actual observed hospitalizations
- **Purple bands**: FluSight-baseline prediction intervals (dashed median)
- **Green bands**: TwoStage-Ensemble prediction intervals (solid median)
- **Band opacity**: Darker = narrower interval (50%), lighter = wider (90%, 98%)

## Ensemble Methodology
The ensemble forecast is created by:
1. Loading all model forecasts from the saved_models directory
2. For each quantile level (0.01, 0.025, ..., 0.99), averaging the forecasted values across all models
3. This creates a combined probabilistic forecast that typically has better calibration than individual models

---

Generated on: `r Sys.time()`
